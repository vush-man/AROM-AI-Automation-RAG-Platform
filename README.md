# AROM â€” AI Automation & RAG Platform

A full-stack AI-powered dashboard that uses **Retrieval-Augmented Generation (RAG)** to answer questions about your documents in real-time. Features a streaming chatbot with Gmail integration, persistent memory, and a premium React UI.

> [!NOTE]
> **This is a demo/prototype version.** The current build showcases core functionality and architecture. Production-level tools, security hardening, and additional features will be added as the project moves into the production phase.

---

## âœ¨ Features

### ğŸ¤– AI Chatbot
- **Real-time Token Streaming** â€” AI responses appear word-by-word via Server-Sent Events (SSE)
- **RAG-Powered Answers** â€” Retrieves relevant context from your documents using FAISS vector search
- **Markdown Rendering** â€” Responses are formatted with bold, italic, lists, code blocks, and more
- **Persistent Memory** â€” Conversation history is retained across sessions using SQLite checkpoints
- **User Fact Extraction** â€” Remembers your name and personal details across conversations
- **Confidence Scoring** â€” Each response includes a confidence percentage and decision level (AUTO / REVIEW / MANUAL)
- **Tool Call Transparency** â€” The UI shows which tools the AI is calling (Document Search, Gmail Analysis) and which source documents were used, in real-time

### ğŸ“§ Gmail Intelligence
- **Email Analysis** â€” Fetches and categorizes emails (invoice, networking, event, promotional)
- **Priority Assignment** â€” Automatically assigns high/medium/low priority to emails
- **Sentiment Detection** â€” Analyzes email sentiment (positive, negative, neutral)
- **Smart Filtering** â€” Searches for important, urgent, or topic-specific emails

### ğŸ” Authentication
- **JWT-Based Auth** â€” Secure signup/login with hashed passwords (bcrypt)
- **Protected Routes** â€” Dashboard pages require authentication
- **Session Persistence** â€” Stays logged in via localStorage tokens

### ğŸ“Š Dashboard
- **AI Chat (Overview)** â€” Main chatbot interface with streaming and feedback
- **Analytics** â€” Visual charts and statistics for query history
- **History** â€” Browse past conversations and responses
- **Feedback System** â€” Thumbs up/down with correction input to refine AI answers

### ğŸ¨ UI/UX
- **Premium Dark Mode** â€” Sleek dark theme with accent colors and glassmorphism effects
- **Vortex Landing Page** â€” Animated particle background on the landing page
- **Responsive Layout** â€” Sidebar navigation with collapsible menu
- **Smooth Animations** â€” Framer Motion transitions and scroll-reveal effects

---

## ğŸ›  Prerequisites

Ensure you have the following installed before starting:

| Tool | Version | Download |
|------|---------|----------|
| **Node.js** | v18+ | [nodejs.org](https://nodejs.org/) |
| **Python** | 3.11+ | [python.org](https://www.python.org/) |
| **Ollama** | Latest | [ollama.com](https://ollama.com/) |
| **Git** | Latest | [git-scm.com](https://git-scm.com/) |

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository
```bash
git clone https://github.com/vush-man/AROM-AI-Automation-RAG-Platform.git
cd AMD-Slingshot
```

### 2. Ollama Models
Pull the required LLM models:
```bash
# Embedding model (for document indexing & search)
ollama pull qwen3-embedding:4b

# Chat model (for generating answers)
ollama pull qwen2.5:3b
```

### 3. Python AI Engine
```bash
cd backend

# Create & activate virtual environment
python -m venv venv

# Windows
.\venv\Scripts\activate
# macOS/Linux
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 4. Node.js Backend
```bash
cd backend
npm install

# Create your environment file
copy .env.example .env        # Windows
# cp .env.example .env        # macOS/Linux
```

Edit the `.env` file and configure:
```env
PORT=5000
JWT_SECRET=your-secret-key-here
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_EMBEDDING_MODEL=qwen3-embedding:4b
OLLAMA_CHAT_MODEL=qwen3:4b
DB_PATH=./db/slingshot.db
TOP_K=5
CONFIDENCE_THRESHOLD=0.5
```

### 5. React Frontend
```bash
cd frontend
npm install
```

---

## ğŸ“„ Document Ingestion

Before using the chatbot, index your documents into the FAISS vector store:

1. Place your files (PDF, DOCX, TXT) into:
   ```
   backend/embeddings/docs/
   ```

2. Run the ingestion script:
   ```bash
   cd backend/rag
   python ingest_docs.py
   ```
   This creates a `faiss_index/` folder inside `backend/rag/` containing your searchable document vectors.

---

## ğŸƒ Running the Application

You need **3 terminal windows** running simultaneously:

### Terminal 1 â€” Python AI Server
```bash
cd backend/rag
python chatbot_server.py
```
> Runs on **http://127.0.0.1:5001**

### Terminal 2 â€” Node.js Backend
```bash
cd backend
npm run dev
```
> Runs on **http://localhost:5000**

### Terminal 3 â€” React Frontend
```bash
cd frontend
npm run dev
```
> Runs on **http://localhost:5173**

**Open your browser at [http://localhost:5173](http://localhost:5173)** ğŸš€

---

## ğŸ“ Project Structure

```
AMD-Slingshot/
â”œâ”€â”€ frontend/                    # React (Vite) frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ landing/         # Landing page sections (Hero, Navbar, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/       # Sidebar, TopHeader
â”‚   â”‚   â”‚   â””â”€â”€ ui/              # Reusable UI components (Vortex, SpotlightCard)
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ LandingPage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginPage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SignupPage.jsx
â”‚   â”‚   â”‚   â””â”€â”€ dashboardpage/   # Overview, Analytics, History, etc.
â”‚   â”‚   â”œâ”€â”€ context/             # AuthContext (JWT state management)
â”‚   â”‚   â”œâ”€â”€ services/            # API client (streaming, feedback, auth)
â”‚   â”‚   â””â”€â”€ hooks/               # Custom hooks (useScrollReveal)
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                     # Node.js + Python backend
â”‚   â”œâ”€â”€ routes/                  # Express API routes
â”‚   â”‚   â”œâ”€â”€ auth.routes.js       # Signup, Login
â”‚   â”‚   â”œâ”€â”€ query.routes.js      # Chat queries (proxies to Python)
â”‚   â”‚   â””â”€â”€ feedback.routes.js   # Thumbs up/down, corrections
â”‚   â”œâ”€â”€ rag/                     # Python AI engine
â”‚   â”‚   â”œâ”€â”€ chatbot.py           # LangGraph chatbot with RAG + Gmail tools
â”‚   â”‚   â”œâ”€â”€ chatbot_server.py    # Flask API wrapper (streaming SSE)
â”‚   â”‚   â”œâ”€â”€ ingest_docs.py       # Document ingestion into FAISS
â”‚   â”‚   â””â”€â”€ faiss_index/         # Vector store (auto-generated)
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ docs/                # Drop your documents here
â”‚   â”‚   â””â”€â”€ embedder.js          # Node.js embedding helper
â”‚   â”œâ”€â”€ db/                      # SQLite database
â”‚   â”œâ”€â”€ auth/                    # JWT middleware
â”‚   â”œâ”€â”€ utils/                   # Logger, cosine similarity
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ package.json             # Node.js dependencies
â”‚   â””â”€â”€ .env.example             # Environment template
â”‚
â””â”€â”€ README.md
```

---

## ğŸ”§ Gmail Integration (Optional)

To enable the Gmail intelligence feature:

1. Create a Google Cloud project and enable the **Gmail API**
2. Download your `credentials.json` and place it in `backend/rag/`
3. Run the chatbot once â€” it will prompt you to authenticate via browser
4. A `token.json` file will be created automatically for future use

Once configured, ask the chatbot things like:
- *"Do I have any important emails?"*
- *"Check my inbox for invoices"*
- *"Show me recent networking emails"*

---

## ğŸ†˜ Troubleshooting

| Issue | Solution |
|-------|----------|
| **"Error connecting to AI backend"** | Ensure `chatbot_server.py` is running on port 5001 |
| **"Ollama not found"** | Make sure the Ollama desktop app is running in the background |
| **Blank page after login** | Clear browser cache or localStorage |
| **FAISS index not found** | Run `python ingest_docs.py` after placing documents in `embeddings/docs/` |
| **Gmail tool errors** | Check that `credentials.json` and `token.json` exist in `backend/rag/` |

---

## ğŸ§° Tech Stack

| Layer | Technologies |
|-------|-------------|
| **Frontend** | React 19, Vite 7, React Router, Framer Motion, Recharts, Lucide Icons |
| **Backend (API)** | Node.js, Express, SQLite3, JWT, bcrypt |
| **AI Engine** | Python, Flask, LangChain, LangGraph, FAISS, Ollama |
| **LLM Models** | Qwen 2.5 (3B chat), Qwen 3 Embedding (4B) |
| **Integrations** | Gmail API (via LangChain Google Community) |

---

## ğŸ—ºï¸ Roadmap

This is a **demo product** â€” the following enhancements are planned for the production release:

- [ ] **Multi-user workspaces** â€” Team-based document collections and shared chat history
- [ ] **Role-based access control** â€” Admin, editor, and viewer permission levels
- [ ] **Cloud deployment** â€” Dockerized setup with CI/CD pipeline
- [ ] **Additional AI tools** â€” Calendar, Slack, and CRM integrations
- [ ] **Advanced RAG** â€” Hybrid search, re-ranking, and chunk-level citations
- [ ] **Production security** â€” Rate limiting, input sanitization, and HTTPS enforcement
- [ ] **PostgreSQL migration** â€” Switch from SQLite to PostgreSQL for scalable, production-grade data storage
- [ ] **File management UI** â€” Upload, preview, and manage documents from the dashboard
- [ ] **Customizable LLM models** â€” Switch between Ollama, OpenAI, and other providers

---

## ğŸ‘¥ Credits

| Contributor | Role |
|-------------|------|
| **Ayan Goswami** | AI Engine, Tools & Embedding Code |
| **Aman Shah** | Backend Development |
| **Om Chaurasia** | Frontend Development |
